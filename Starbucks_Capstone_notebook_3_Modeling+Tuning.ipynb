{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starbucks Capstone Challenge\n",
    "\n",
    "### Introduction\n",
    "\n",
    "This data set contains simulated data that mimics customer behavior on the Starbucks rewards mobile app. Once every few days, Starbucks sends out an offer to users of the mobile app. An offer can be merely an advertisement for a drink or an actual offer such as a discount or BOGO (buy one get one free). Some users might not receive any offer during certain weeks. \n",
    "\n",
    "Not all users receive the same offer, and that is the challenge to solve with this data set.\n",
    "\n",
    "Your task is to combine transaction, demographic and offer data to determine which demographic groups respond best to which offer type. This data set is a simplified version of the real Starbucks app because the underlying simulator only has one product whereas Starbucks actually sells dozens of products.\n",
    "\n",
    "Every offer has a validity period before the offer expires. As an example, a BOGO offer might be valid for only 5 days. You'll see in the data set that informational offers have a validity period even though these ads are merely providing information about a product; for example, if an informational offer has 7 days of validity, you can assume the customer is feeling the influence of the offer for 7 days after receiving the advertisement.\n",
    "\n",
    "You'll be given transactional data showing user purchases made on the app including the timestamp of purchase and the amount of money spent on a purchase. This transactional data also has a record for each offer that a user receives as well as a record for when a user actually views the offer. There are also records for when a user completes an offer. \n",
    "\n",
    "Keep in mind as well that someone using the app might make a purchase through the app without having received an offer or seen an offer.\n",
    "\n",
    "### Example\n",
    "\n",
    "To give an example, a user could receive a discount offer buy 10 dollars get 2 off on Monday. The offer is valid for 10 days from receipt. If the customer accumulates at least 10 dollars in purchases during the validity period, the customer completes the offer.\n",
    "\n",
    "However, there are a few things to watch out for in this data set. Customers do not opt into the offers that they receive; in other words, a user can receive an offer, never actually view the offer, and still complete the offer. For example, a user might receive the \"buy 10 dollars get 2 dollars off offer\", but the user never opens the offer during the 10 day validity period. The customer spends 15 dollars during those ten days. There will be an offer completion record in the data set; however, the customer was not influenced by the offer because the customer never viewed the offer.\n",
    "\n",
    "### Cleaning\n",
    "\n",
    "This makes data cleaning especially important and tricky.\n",
    "\n",
    "You'll also want to take into account that some demographic groups will make purchases even if they don't receive an offer. From a business perspective, if a customer is going to make a 10 dollar purchase without an offer anyway, you wouldn't want to send a buy 10 dollars get 2 dollars off offer. You'll want to try to assess what a certain demographic group will buy when not receiving any offers.\n",
    "\n",
    "### Final Advice\n",
    "\n",
    "Because this is a capstone project, you are free to analyze the data any way you see fit. For example, you could build a machine learning model that predicts how much someone will spend based on demographics and offer type. Or you could build a model that predicts whether or not someone will respond to an offer. Or, you don't need to build a machine learning model at all. You could develop a set of heuristics that determine what offer you should send to each customer (i.e., 75 percent of women customers who were 35 years old responded to offer A vs 40 percent from the same demographic to offer B, so send offer A)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sets\n",
    "\n",
    "The data is contained in three files:\n",
    "\n",
    "* portfolio.json - containing offer ids and meta data about each offer (duration, type, etc.)\n",
    "* profile.json - demographic data for each customer\n",
    "* transcript.json - records for transactions, offers received, offers viewed, and offers completed\n",
    "\n",
    "Here is the schema and explanation of each variable in the files:\n",
    "\n",
    "**portfolio.json**\n",
    "* id (string) - offer id\n",
    "* offer_type (string) - type of offer ie BOGO, discount, informational\n",
    "* difficulty (int) - minimum required spend to complete an offer\n",
    "* reward (int) - reward given for completing an offer\n",
    "* duration (int) - time for offer to be open, in days\n",
    "* channels (list of strings)\n",
    "\n",
    "**profile.json**\n",
    "* age (int) - age of the customer \n",
    "* became_member_on (int) - date when customer created an app account\n",
    "* gender (str) - gender of the customer (note some entries contain 'O' for other rather than M or F)\n",
    "* id (str) - customer id\n",
    "* income (float) - customer's income\n",
    "\n",
    "**transcript.json**\n",
    "* event (str) - record description (ie transaction, offer received, offer viewed, etc.)\n",
    "* person (str) - customer id\n",
    "* time (int) - time in hours since start of test. The data begins at time t=0\n",
    "* value - (dict of strings) - either an offer id or transaction amount depending on the record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import io\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-2-634441263192\n"
     ]
    }
   ],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# Name of directory created to save your features data\n",
    "data_dir = 'starbucks_data'\n",
    "\n",
    "# Set prefix, a descriptive name for a directory  \n",
    "prefix = 'capstone'\n",
    "\n",
    "# Upload dataset to S3\n",
    "train_location = sagemaker_session.upload_data(os.path.join(data_dir, 'train.csv'), key_prefix=prefix)\n",
    "valid_location = sagemaker_session.upload_data(os.path.join(data_dir, 'valid.csv'), key_prefix=prefix)\n",
    "test_location = sagemaker_session.upload_data(os.path.join(data_dir, 'test.csv'), key_prefix=prefix)\n",
    "\n",
    "# Initialize the default bucket to store the trained model artifacts later\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from local directory\n",
    "# Needed for LinearLearner built-in model\n",
    "train = pd.read_csv('starbucks_data/train.csv', header=None)\n",
    "X_train = train.drop([0], axis=1).to_numpy('float32')\n",
    "y_train = train[0].to_numpy('float32')\n",
    "\n",
    "valid = pd.read_csv('starbucks_data/valid.csv', header=None)\n",
    "X_valid = valid.drop([0], axis=1).to_numpy('float32')\n",
    "y_valid = valid[0].to_numpy('float32')\n",
    "\n",
    "test = pd.read_csv('starbucks_data/test.csv', header=None)\n",
    "X_test = test.drop([0], axis=1).to_numpy('float32')\n",
    "y_test = test[0].to_numpy('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import LinearLearner\n",
    "from sagemaker import LinearLearner\n",
    "\n",
    "# specify an output path\n",
    "prefix = 'capstone-starbucks'\n",
    "output_path = 's3://{}/{}'.format(bucket, prefix)\n",
    "\n",
    "# instantiate LinearLearner\n",
    "linear = LinearLearner(\n",
    "    role=role,\n",
    "    train_instance_count=1, \n",
    "    train_instance_type='ml.c4.xlarge',\n",
    "    predictor_type='regressor',\n",
    "    output_path=output_path,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    optimizer='sgd',\n",
    "    epochs=100,\n",
    "    #learning_rate=0.01,\n",
    "    #loss='rmse',\n",
    "    #early_stopping_patience=3,\n",
    "    #early_stopping_tolerance=0.005\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create RecordSet\n",
    "#formatted_train_data = linear.record_set(train=X_train, labels=y_train)\n",
    "#formatted_valid_data = linear.record_set(train=X_valid, labels=y_valid, channel='validation')\n",
    "#formatted_test_data = linear.record_set(train=X_test, labels=y_test, channel='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Hyperparameter tunier modules\n",
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "linear_hp_tuner = HyperparameterTuner(\n",
    "    estimator=linear,\n",
    "    objective_metric_name='validation:objective_loss',\n",
    "    objective_type='Minimize',\n",
    "    max_jobs=10,\n",
    "    max_parallel_jobs=2,\n",
    "    hyperparameter_ranges={\n",
    "        'wd':ContinuousParameter(1e-3,1e1)#,\n",
    "        #'learning_rate':ContinuousParameter(1e-5,0.1)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the hyperparameter tuner, provide the validation channel as well\n",
    "linear_hp_tuner.fit([formatted_train_data, formatted_valid_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "linear_hp_tuner.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'linear-learner-200331-2133-002-253df336'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_hp_tuner.best_training_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-31 21:36:35 Starting - Preparing the instances for training\n",
      "2020-03-31 21:36:35 Downloading - Downloading input data\n",
      "2020-03-31 21:36:35 Training - Training image download completed. Training in progress.\n",
      "2020-03-31 21:36:35 Uploading - Uploading generated training model\n",
      "2020-03-31 21:36:35 Completed - Training job completed\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:25 INFO 140475577349952] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'loss_insensitivity': u'0.01', u'epochs': u'15', u'feature_dim': u'auto', u'init_bias': u'0.0', u'lr_scheduler_factor': u'auto', u'num_calibration_samples': u'10000000', u'accuracy_top_k': u'3', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'num_point_for_scaler': u'10000', u'_log_level': u'info', u'quantile': u'0.5', u'bias_lr_mult': u'auto', u'lr_scheduler_step': u'auto', u'init_method': u'uniform', u'init_sigma': u'0.01', u'lr_scheduler_minimum_lr': u'auto', u'target_recall': u'0.8', u'num_models': u'auto', u'early_stopping_patience': u'3', u'momentum': u'auto', u'unbias_label': u'auto', u'wd': u'auto', u'optimizer': u'auto', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.001', u'learning_rate': u'auto', u'_kvstore': u'auto', u'normalize_data': u'true', u'binary_classifier_model_selection_criteria': u'accuracy', u'use_lr_scheduler': u'true', u'target_precision': u'0.8', u'unbias_data': u'auto', u'init_scale': u'0.07', u'bias_wd_mult': u'auto', u'f_beta': u'1.0', u'mini_batch_size': u'1000', u'huber_delta': u'1.0', u'num_classes': u'1', u'beta_1': u'auto', u'loss': u'auto', u'beta_2': u'auto', u'_enable_profiler': u'false', u'normalize_label': u'auto', u'_num_gpus': u'auto', u'balance_multiclass_weights': u'false', u'positive_example_weight_mult': u'1.0', u'l1': u'auto', u'margin': u'1.0'}\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:25 INFO 140475577349952] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {u'wd': u'4.420034520072575e-06', u'optimizer': u'sgd', u'predictor_type': u'regressor', u'_tuning_objective_metric': u'validation:objective_loss', u'epochs': u'100', u'feature_dim': u'8', u'mini_batch_size': u'1000'}\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:25 INFO 140475577349952] Final configuration: {u'loss_insensitivity': u'0.01', u'epochs': u'100', u'feature_dim': u'8', u'init_bias': u'0.0', u'lr_scheduler_factor': u'auto', u'num_calibration_samples': u'10000000', u'accuracy_top_k': u'3', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'num_point_for_scaler': u'10000', u'_log_level': u'info', u'quantile': u'0.5', u'bias_lr_mult': u'auto', u'lr_scheduler_step': u'auto', u'init_method': u'uniform', u'init_sigma': u'0.01', u'lr_scheduler_minimum_lr': u'auto', u'target_recall': u'0.8', u'num_models': u'auto', u'early_stopping_patience': u'3', u'momentum': u'auto', u'unbias_label': u'auto', u'wd': u'4.420034520072575e-06', u'optimizer': u'sgd', u'_tuning_objective_metric': u'validation:objective_loss', u'early_stopping_tolerance': u'0.001', u'learning_rate': u'auto', u'_kvstore': u'auto', u'normalize_data': u'true', u'binary_classifier_model_selection_criteria': u'accuracy', u'use_lr_scheduler': u'true', u'target_precision': u'0.8', u'unbias_data': u'auto', u'init_scale': u'0.07', u'bias_wd_mult': u'auto', u'f_beta': u'1.0', u'mini_batch_size': u'1000', u'huber_delta': u'1.0', u'num_classes': u'1', u'predictor_type': u'regressor', u'beta_1': u'auto', u'loss': u'auto', u'beta_2': u'auto', u'_enable_profiler': u'false', u'normalize_label': u'auto', u'_num_gpus': u'auto', u'balance_multiclass_weights': u'false', u'positive_example_weight_mult': u'1.0', u'l1': u'auto', u'margin': u'1.0'}\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:25 WARNING 140475577349952] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:25 INFO 140475577349952] Using default worker.\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:25 INFO 140475577349952] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[2020-03-31 21:36:25.714] [tensorio] [warning] TensorIO is already initialized; ignoring the initialization routine.\u001b[0m\n",
      "\u001b[34m[2020-03-31 21:36:25.746] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 35, \"num_examples\": 1, \"num_bytes\": 76000}\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:25 INFO 140475577349952] Create Store: local\u001b[0m\n",
      "\u001b[34m[2020-03-31 21:36:25.799] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 52, \"num_examples\": 11, \"num_bytes\": 836000}\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:25 INFO 140475577349952] Scaler algorithm parameters\n",
      " <algorithm.scaler.ScalerAlgorithmStable object at 0x7fc2a743cc10>\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:25 INFO 140475577349952] Scaling model computed with parameters:\n",
      " {'stdev_weight': \u001b[0m\n",
      "\u001b[34m[0.9983791  1.006053   1.0053189  1.001248   0.9997082  0.99922436\n",
      " 1.0006756  0.9975932 ]\u001b[0m\n",
      "\u001b[34m<NDArray 8 @cpu(0)>, 'stdev_label': \u001b[0m\n",
      "\u001b[34m[67.98524]\u001b[0m\n",
      "\u001b[34m<NDArray 1 @cpu(0)>, 'mean_label': \u001b[0m\n",
      "\u001b[34m[44.239727]\u001b[0m\n",
      "\u001b[34m<NDArray 1 @cpu(0)>, 'mean_weight': \u001b[0m\n",
      "\u001b[34m[ 9.8655095e-05  3.3233750e-03  7.3467512e-03 -1.1624011e-02\n",
      "  2.0012963e-03 -4.3603312e-03  7.0660538e-03 -1.3261963e-02]\u001b[0m\n",
      "\u001b[34m<NDArray 8 @cpu(0)>}\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:25 INFO 140475577349952] nvidia-smi took: 0.0252280235291 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:25 INFO 140475577349952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 11, \"sum\": 11.0, \"min\": 11}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Total Records Seen\": {\"count\": 1, \"max\": 12000, \"sum\": 12000.0, \"min\": 12000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 11000, \"sum\": 11000.0, \"min\": 11000}, \"Reset Count\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}}, \"EndTime\": 1585690585.843858, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\"}, \"StartTime\": 1585690585.843829}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-03-31 21:36:25.897] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 3, \"duration\": 53, \"num_examples\": 22, \"num_bytes\": 1597520}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.0402187950497581, \"sum\": 1.0402187950497581, \"min\": 1.0402187950497581}}, \"EndTime\": 1585690585.897526, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1585690585.897462}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:25 INFO 140475577349952] #quality_metric: host=algo-1, epoch=0, train mse_objective <loss>=1.04021879505\u001b[0m\n",
      "\u001b[34m[2020-03-31 21:36:25.899] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 0, \"duration\": 184, \"num_examples\": 1, \"num_bytes\": 76000}\u001b[0m\n",
      "\u001b[34m[2020-03-31 21:36:25.917] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 2, \"duration\": 17, \"num_examples\": 6, \"num_bytes\": 399456}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_mse_objective\": {\"count\": 1, \"max\": 4160.535982686453, \"sum\": 4160.535982686453, \"min\": 4160.535982686453}}, \"EndTime\": 1585690585.918066, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1585690585.918029}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:25 INFO 140475577349952] #quality_metric: host=algo-1, epoch=0, validation mse_objective <loss>=4160.53598269\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:25 INFO 140475577349952] #early_stopping_criteria_metric: host=algo-1, epoch=0, criteria=mse_objective, value=4160.53598269\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:25 INFO 140475577349952] Epoch 0: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:25 INFO 140475577349952] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 22, \"sum\": 22.0, \"min\": 22}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 22, \"sum\": 22.0, \"min\": 22}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 21020, \"sum\": 21020.0, \"min\": 21020}, \"Total Batches Seen\": {\"count\": 1, \"max\": 34, \"sum\": 34.0, \"min\": 34}, \"Total Records Seen\": {\"count\": 1, \"max\": 33020, \"sum\": 33020.0, \"min\": 33020}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 21020, \"sum\": 21020.0, \"min\": 21020}, \"Reset Count\": {\"count\": 1, \"max\": 3, \"sum\": 3.0, \"min\": 3}}, \"EndTime\": 1585690585.919893, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1585690585.844134}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:25 INFO 140475577349952] #throughput_metric: host=algo-1, train throughput=276921.315815 records/second\u001b[0m\n",
      "\u001b[34m[2020-03-31 21:36:25.981] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 5, \"duration\": 61, \"num_examples\": 22, \"num_bytes\": 1597520}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.0272494172595796, \"sum\": 1.0272494172595796, \"min\": 1.0272494172595796}}, \"EndTime\": 1585690585.981586, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1585690585.98154}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:25 INFO 140475577349952] #quality_metric: host=algo-1, epoch=1, train mse_objective <loss>=1.02724941726\u001b[0m\n",
      "\u001b[34m[2020-03-31 21:36:25.995] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 5, \"duration\": 12, \"num_examples\": 6, \"num_bytes\": 399456}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_mse_objective\": {\"count\": 1, \"max\": 4115.091966324201, \"sum\": 4115.091966324201, \"min\": 4115.091966324201}}, \"EndTime\": 1585690585.996172, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1585690585.996148}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:25 INFO 140475577349952] #quality_metric: host=algo-1, epoch=1, validation mse_objective <loss>=4115.09196632\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:25 INFO 140475577349952] #early_stopping_criteria_metric: host=algo-1, epoch=1, criteria=mse_objective, value=4115.09196632\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:25 INFO 140475577349952] Epoch 1: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:25 INFO 140475577349952] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 22, \"sum\": 22.0, \"min\": 22}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 22, \"sum\": 22.0, \"min\": 22}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 21020, \"sum\": 21020.0, \"min\": 21020}, \"Total Batches Seen\": {\"count\": 1, \"max\": 56, \"sum\": 56.0, \"min\": 56}, \"Total Records Seen\": {\"count\": 1, \"max\": 54040, \"sum\": 54040.0, \"min\": 54040}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 21020, \"sum\": 21020.0, \"min\": 21020}, \"Reset Count\": {\"count\": 1, \"max\": 4, \"sum\": 4.0, \"min\": 4}}, \"EndTime\": 1585690585.997557, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1585690585.920214}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:25 INFO 140475577349952] #throughput_metric: host=algo-1, train throughput=271288.867664 records/second\u001b[0m\n",
      "\u001b[34m[2020-03-31 21:36:26.055] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 7, \"duration\": 57, \"num_examples\": 22, \"num_bytes\": 1597520}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.0179065609886533, \"sum\": 1.0179065609886533, \"min\": 1.0179065609886533}}, \"EndTime\": 1585690586.055921, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1585690586.055881}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #quality_metric: host=algo-1, epoch=2, train mse_objective <loss>=1.01790656099\u001b[0m\n",
      "\u001b[34m[2020-03-31 21:36:26.071] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 8, \"duration\": 13, \"num_examples\": 6, \"num_bytes\": 399456}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_mse_objective\": {\"count\": 1, \"max\": 4082.0866152968038, \"sum\": 4082.0866152968038, \"min\": 4082.0866152968038}}, \"EndTime\": 1585690586.071637, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1585690586.071607}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #quality_metric: host=algo-1, epoch=2, validation mse_objective <loss>=4082.0866153\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #early_stopping_criteria_metric: host=algo-1, epoch=2, criteria=mse_objective, value=4082.0866153\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] Epoch 2: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 22, \"sum\": 22.0, \"min\": 22}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 22, \"sum\": 22.0, \"min\": 22}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 21020, \"sum\": 21020.0, \"min\": 21020}, \"Total Batches Seen\": {\"count\": 1, \"max\": 78, \"sum\": 78.0, \"min\": 78}, \"Total Records Seen\": {\"count\": 1, \"max\": 75060, \"sum\": 75060.0, \"min\": 75060}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 21020, \"sum\": 21020.0, \"min\": 21020}, \"Reset Count\": {\"count\": 1, \"max\": 5, \"sum\": 5.0, \"min\": 5}}, \"EndTime\": 1585690586.073013, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1585690585.997816}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #throughput_metric: host=algo-1, train throughput=279053.83959 records/second\u001b[0m\n",
      "\u001b[34m[2020-03-31 21:36:26.131] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 9, \"duration\": 58, \"num_examples\": 22, \"num_bytes\": 1597520}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.0109900992257255, \"sum\": 1.0109900992257255, \"min\": 1.0109900992257255}}, \"EndTime\": 1585690586.131943, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1585690586.131883}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #quality_metric: host=algo-1, epoch=3, train mse_objective <loss>=1.01099009923\u001b[0m\n",
      "\u001b[34m[2020-03-31 21:36:26.150] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 11, \"duration\": 17, \"num_examples\": 6, \"num_bytes\": 399456}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_mse_objective\": {\"count\": 1, \"max\": 4057.6799134322678, \"sum\": 4057.6799134322678, \"min\": 4057.6799134322678}}, \"EndTime\": 1585690586.151441, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1585690586.151408}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #quality_metric: host=algo-1, epoch=3, validation mse_objective <loss>=4057.67991343\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #early_stopping_criteria_metric: host=algo-1, epoch=3, criteria=mse_objective, value=4057.67991343\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] Epoch 3: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 22, \"sum\": 22.0, \"min\": 22}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 22, \"sum\": 22.0, \"min\": 22}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 21020, \"sum\": 21020.0, \"min\": 21020}, \"Total Batches Seen\": {\"count\": 1, \"max\": 100, \"sum\": 100.0, \"min\": 100}, \"Total Records Seen\": {\"count\": 1, \"max\": 96080, \"sum\": 96080.0, \"min\": 96080}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 21020, \"sum\": 21020.0, \"min\": 21020}, \"Reset Count\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}}, \"EndTime\": 1585690586.153202, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1585690586.073306}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #throughput_metric: host=algo-1, train throughput=262457.713132 records/second\u001b[0m\n",
      "\u001b[34m[2020-03-31 21:36:26.212] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 11, \"duration\": 58, \"num_examples\": 22, \"num_bytes\": 1597520}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.0057605663481213, \"sum\": 1.0057605663481213, \"min\": 1.0057605663481213}}, \"EndTime\": 1585690586.212757, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1585690586.212716}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #quality_metric: host=algo-1, epoch=4, train mse_objective <loss>=1.00576056635\u001b[0m\n",
      "\u001b[34m[2020-03-31 21:36:26.227] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 14, \"duration\": 13, \"num_examples\": 6, \"num_bytes\": 399456}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_mse_objective\": {\"count\": 1, \"max\": 4039.332382039574, \"sum\": 4039.332382039574, \"min\": 4039.332382039574}}, \"EndTime\": 1585690586.227429, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1585690586.227405}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #quality_metric: host=algo-1, epoch=4, validation mse_objective <loss>=4039.33238204\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #early_stopping_criteria_metric: host=algo-1, epoch=4, criteria=mse_objective, value=4039.33238204\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] Epoch 4: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 22, \"sum\": 22.0, \"min\": 22}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 22, \"sum\": 22.0, \"min\": 22}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 21020, \"sum\": 21020.0, \"min\": 21020}, \"Total Batches Seen\": {\"count\": 1, \"max\": 122, \"sum\": 122.0, \"min\": 122}, \"Total Records Seen\": {\"count\": 1, \"max\": 117100, \"sum\": 117100.0, \"min\": 117100}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 21020, \"sum\": 21020.0, \"min\": 21020}, \"Reset Count\": {\"count\": 1, \"max\": 7, \"sum\": 7.0, \"min\": 7}}, \"EndTime\": 1585690586.228755, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1585690586.153623}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #throughput_metric: host=algo-1, train throughput=279094.474982 records/second\u001b[0m\n",
      "\u001b[34m[2020-03-31 21:36:26.286] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 13, \"duration\": 57, \"num_examples\": 22, \"num_bytes\": 1597520}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 1.0017313363211495, \"sum\": 1.0017313363211495, \"min\": 1.0017313363211495}}, \"EndTime\": 1585690586.286831, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1585690586.286788}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #quality_metric: host=algo-1, epoch=5, train mse_objective <loss>=1.00173133632\u001b[0m\n",
      "\u001b[34m[2020-03-31 21:36:26.303] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 17, \"duration\": 14, \"num_examples\": 6, \"num_bytes\": 399456}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_mse_objective\": {\"count\": 1, \"max\": 4025.32025304414, \"sum\": 4025.32025304414, \"min\": 4025.32025304414}}, \"EndTime\": 1585690586.303544, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1585690586.303519}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #quality_metric: host=algo-1, epoch=5, validation mse_objective <loss>=4025.32025304\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #early_stopping_criteria_metric: host=algo-1, epoch=5, criteria=mse_objective, value=4025.32025304\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] Epoch 5: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 22, \"sum\": 22.0, \"min\": 22}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 22, \"sum\": 22.0, \"min\": 22}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 21020, \"sum\": 21020.0, \"min\": 21020}, \"Total Batches Seen\": {\"count\": 1, \"max\": 144, \"sum\": 144.0, \"min\": 144}, \"Total Records Seen\": {\"count\": 1, \"max\": 138120, \"sum\": 138120.0, \"min\": 138120}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 21020, \"sum\": 21020.0, \"min\": 21020}, \"Reset Count\": {\"count\": 1, \"max\": 8, \"sum\": 8.0, \"min\": 8}}, \"EndTime\": 1585690586.304773, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1585690586.229038}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #throughput_metric: host=algo-1, train throughput=277085.805949 records/second\u001b[0m\n",
      "\u001b[34m[2020-03-31 21:36:26.369] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 15, \"duration\": 64, \"num_examples\": 22, \"num_bytes\": 1597520}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9985734122140068, \"sum\": 0.9985734122140068, \"min\": 0.9985734122140068}}, \"EndTime\": 1585690586.369368, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1585690586.369307}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #quality_metric: host=algo-1, epoch=6, train mse_objective <loss>=0.998573412214\u001b[0m\n",
      "\u001b[34m[2020-03-31 21:36:26.386] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 20, \"duration\": 15, \"num_examples\": 6, \"num_bytes\": 399456}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_mse_objective\": {\"count\": 1, \"max\": 4014.466300418569, \"sum\": 4014.466300418569, \"min\": 4014.466300418569}}, \"EndTime\": 1585690586.387193, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1585690586.387164}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #quality_metric: host=algo-1, epoch=6, validation mse_objective <loss>=4014.46630042\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #early_stopping_criteria_metric: host=algo-1, epoch=6, criteria=mse_objective, value=4014.46630042\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] Epoch 6: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 22, \"sum\": 22.0, \"min\": 22}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 22, \"sum\": 22.0, \"min\": 22}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 21020, \"sum\": 21020.0, \"min\": 21020}, \"Total Batches Seen\": {\"count\": 1, \"max\": 166, \"sum\": 166.0, \"min\": 166}, \"Total Records Seen\": {\"count\": 1, \"max\": 159140, \"sum\": 159140.0, \"min\": 159140}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 21020, \"sum\": 21020.0, \"min\": 21020}, \"Reset Count\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}}, \"EndTime\": 1585690586.38857, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1585690586.305021}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #throughput_metric: host=algo-1, train throughput=251216.042399 records/second\u001b[0m\n",
      "\u001b[34m[2020-03-31 21:36:26.459] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 17, \"duration\": 70, \"num_examples\": 22, \"num_bytes\": 1597520}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9960600309826079, \"sum\": 0.9960600309826079, \"min\": 0.9960600309826079}}, \"EndTime\": 1585690586.459762, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1585690586.45971}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #quality_metric: host=algo-1, epoch=7, train mse_objective <loss>=0.996060030983\u001b[0m\n",
      "\u001b[34m[2020-03-31 21:36:26.481] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 23, \"duration\": 19, \"num_examples\": 6, \"num_bytes\": 399456}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_mse_objective\": {\"count\": 1, \"max\": 4005.9539811643835, \"sum\": 4005.9539811643835, \"min\": 4005.9539811643835}}, \"EndTime\": 1585690586.481952, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1585690586.48191}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #quality_metric: host=algo-1, epoch=7, validation mse_objective <loss>=4005.95398116\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #early_stopping_criteria_metric: host=algo-1, epoch=7, criteria=mse_objective, value=4005.95398116\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] Epoch 7: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 22, \"sum\": 22.0, \"min\": 22}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 22, \"sum\": 22.0, \"min\": 22}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 21020, \"sum\": 21020.0, \"min\": 21020}, \"Total Batches Seen\": {\"count\": 1, \"max\": 188, \"sum\": 188.0, \"min\": 188}, \"Total Records Seen\": {\"count\": 1, \"max\": 180160, \"sum\": 180160.0, \"min\": 180160}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 21020, \"sum\": 21020.0, \"min\": 21020}, \"Reset Count\": {\"count\": 1, \"max\": 10, \"sum\": 10.0, \"min\": 10}}, \"EndTime\": 1585690586.484168, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1585690586.388842}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #throughput_metric: host=algo-1, train throughput=219736.633078 records/second\u001b[0m\n",
      "\u001b[34m[2020-03-31 21:36:26.560] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 19, \"duration\": 75, \"num_examples\": 22, \"num_bytes\": 1597520}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9940342160179502, \"sum\": 0.9940342160179502, \"min\": 0.9940342160179502}}, \"EndTime\": 1585690586.560204, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1585690586.560162}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #quality_metric: host=algo-1, epoch=8, train mse_objective <loss>=0.994034216018\u001b[0m\n",
      "\u001b[34m[2020-03-31 21:36:26.580] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 26, \"duration\": 19, \"num_examples\": 6, \"num_bytes\": 399456}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_mse_objective\": {\"count\": 1, \"max\": 3999.2082144216133, \"sum\": 3999.2082144216133, \"min\": 3999.2082144216133}}, \"EndTime\": 1585690586.5815, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1585690586.581461}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #quality_metric: host=algo-1, epoch=8, validation mse_objective <loss>=3999.20821442\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #early_stopping_criteria_metric: host=algo-1, epoch=8, criteria=mse_objective, value=3999.20821442\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] Epoch 8: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 22, \"sum\": 22.0, \"min\": 22}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 22, \"sum\": 22.0, \"min\": 22}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 21020, \"sum\": 21020.0, \"min\": 21020}, \"Total Batches Seen\": {\"count\": 1, \"max\": 210, \"sum\": 210.0, \"min\": 210}, \"Total Records Seen\": {\"count\": 1, \"max\": 201180, \"sum\": 201180.0, \"min\": 201180}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 21020, \"sum\": 21020.0, \"min\": 21020}, \"Reset Count\": {\"count\": 1, \"max\": 11, \"sum\": 11.0, \"min\": 11}}, \"EndTime\": 1585690586.583413, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1585690586.484756}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #throughput_metric: host=algo-1, train throughput=212765.993069 records/second\u001b[0m\n",
      "\u001b[34m[2020-03-31 21:36:26.652] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 21, \"duration\": 69, \"num_examples\": 22, \"num_bytes\": 1597520}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9923817676362537, \"sum\": 0.9923817676362537, \"min\": 0.9923817676362537}}, \"EndTime\": 1585690586.653105, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1585690586.653012}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #quality_metric: host=algo-1, epoch=9, train mse_objective <loss>=0.992381767636\u001b[0m\n",
      "\u001b[34m[2020-03-31 21:36:26.672] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 29, \"duration\": 17, \"num_examples\": 6, \"num_bytes\": 399456}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_mse_objective\": {\"count\": 1, \"max\": 3993.8137604642316, \"sum\": 3993.8137604642316, \"min\": 3993.8137604642316}}, \"EndTime\": 1585690586.673295, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1585690586.673263}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #quality_metric: host=algo-1, epoch=9, validation mse_objective <loss>=3993.81376046\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #early_stopping_criteria_metric: host=algo-1, epoch=9, criteria=mse_objective, value=3993.81376046\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] Epoch 9: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 22, \"sum\": 22.0, \"min\": 22}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 22, \"sum\": 22.0, \"min\": 22}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 21020, \"sum\": 21020.0, \"min\": 21020}, \"Total Batches Seen\": {\"count\": 1, \"max\": 232, \"sum\": 232.0, \"min\": 232}, \"Total Records Seen\": {\"count\": 1, \"max\": 222200, \"sum\": 222200.0, \"min\": 222200}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 21020, \"sum\": 21020.0, \"min\": 21020}, \"Reset Count\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}}, \"EndTime\": 1585690586.674853, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1585690586.583673}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #throughput_metric: host=algo-1, train throughput=230088.784707 records/second\u001b[0m\n",
      "\u001b[34m[2020-03-31 21:36:26.748] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 23, \"duration\": 72, \"num_examples\": 22, \"num_bytes\": 1597520}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9910201721191406, \"sum\": 0.9910201721191406, \"min\": 0.9910201721191406}}, \"EndTime\": 1585690586.748461, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1585690586.748418}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #quality_metric: host=algo-1, epoch=10, train mse_objective <loss>=0.991020172119\u001b[0m\n",
      "\u001b[34m[2020-03-31 21:36:26.770] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 32, \"duration\": 20, \"num_examples\": 6, \"num_bytes\": 399456}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_mse_objective\": {\"count\": 1, \"max\": 3989.4656820776254, \"sum\": 3989.4656820776254, \"min\": 3989.4656820776254}}, \"EndTime\": 1585690586.771, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1585690586.770961}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #quality_metric: host=algo-1, epoch=10, validation mse_objective <loss>=3989.46568208\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #early_stopping_criteria_metric: host=algo-1, epoch=10, criteria=mse_objective, value=3989.46568208\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] Epoch 10: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 22, \"sum\": 22.0, \"min\": 22}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 22, \"sum\": 22.0, \"min\": 22}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 21020, \"sum\": 21020.0, \"min\": 21020}, \"Total Batches Seen\": {\"count\": 1, \"max\": 254, \"sum\": 254.0, \"min\": 254}, \"Total Records Seen\": {\"count\": 1, \"max\": 243220, \"sum\": 243220.0, \"min\": 243220}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 21020, \"sum\": 21020.0, \"min\": 21020}, \"Reset Count\": {\"count\": 1, \"max\": 13, \"sum\": 13.0, \"min\": 13}}, \"EndTime\": 1585690586.772542, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1585690586.675196}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #throughput_metric: host=algo-1, train throughput=215638.593134 records/second\u001b[0m\n",
      "\u001b[34m[2020-03-31 21:36:26.862] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 25, \"duration\": 89, \"num_examples\": 22, \"num_bytes\": 1597520}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9898873276483445, \"sum\": 0.9898873276483445, \"min\": 0.9898873276483445}}, \"EndTime\": 1585690586.86313, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1585690586.86308}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #quality_metric: host=algo-1, epoch=11, train mse_objective <loss>=0.989887327648\u001b[0m\n",
      "\u001b[34m[2020-03-31 21:36:26.885] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 35, \"duration\": 16, \"num_examples\": 6, \"num_bytes\": 399456}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_mse_objective\": {\"count\": 1, \"max\": 3985.930270167428, \"sum\": 3985.930270167428, \"min\": 3985.930270167428}}, \"EndTime\": 1585690586.885837, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1585690586.885808}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #quality_metric: host=algo-1, epoch=11, validation mse_objective <loss>=3985.93027017\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #early_stopping_criteria_metric: host=algo-1, epoch=11, criteria=mse_objective, value=3985.93027017\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 22, \"sum\": 22.0, \"min\": 22}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 22, \"sum\": 22.0, \"min\": 22}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 21020, \"sum\": 21020.0, \"min\": 21020}, \"Total Batches Seen\": {\"count\": 1, \"max\": 276, \"sum\": 276.0, \"min\": 276}, \"Total Records Seen\": {\"count\": 1, \"max\": 264240, \"sum\": 264240.0, \"min\": 264240}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 21020, \"sum\": 21020.0, \"min\": 21020}, \"Reset Count\": {\"count\": 1, \"max\": 14, \"sum\": 14.0, \"min\": 14}}, \"EndTime\": 1585690586.886546, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1585690586.772816}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #throughput_metric: host=algo-1, train throughput=184620.975914 records/second\u001b[0m\n",
      "\u001b[34m[2020-03-31 21:36:26.963] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 27, \"duration\": 76, \"num_examples\": 22, \"num_bytes\": 1597520}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9889378952752976, \"sum\": 0.9889378952752976, \"min\": 0.9889378952752976}}, \"EndTime\": 1585690586.963368, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1585690586.96332}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #quality_metric: host=algo-1, epoch=12, train mse_objective <loss>=0.988937895275\u001b[0m\n",
      "\u001b[34m[2020-03-31 21:36:26.982] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 38, \"duration\": 17, \"num_examples\": 6, \"num_bytes\": 399456}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_mse_objective\": {\"count\": 1, \"max\": 3983.0456383181127, \"sum\": 3983.0456383181127, \"min\": 3983.0456383181127}}, \"EndTime\": 1585690586.982823, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1585690586.982788}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #quality_metric: host=algo-1, epoch=12, validation mse_objective <loss>=3983.04563832\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #early_stopping_criteria_metric: host=algo-1, epoch=12, criteria=mse_objective, value=3983.04563832\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 22, \"sum\": 22.0, \"min\": 22}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 22, \"sum\": 22.0, \"min\": 22}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 21020, \"sum\": 21020.0, \"min\": 21020}, \"Total Batches Seen\": {\"count\": 1, \"max\": 298, \"sum\": 298.0, \"min\": 298}, \"Total Records Seen\": {\"count\": 1, \"max\": 285260, \"sum\": 285260.0, \"min\": 285260}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 21020, \"sum\": 21020.0, \"min\": 21020}, \"Reset Count\": {\"count\": 1, \"max\": 15, \"sum\": 15.0, \"min\": 15}}, \"EndTime\": 1585690586.983605, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1585690586.886818}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:26 INFO 140475577349952] #throughput_metric: host=algo-1, train throughput=216888.94102 records/second\u001b[0m\n",
      "\u001b[34m[2020-03-31 21:36:27.060] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 29, \"duration\": 76, \"num_examples\": 22, \"num_bytes\": 1597520}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9881361752464658, \"sum\": 0.9881361752464658, \"min\": 0.9881361752464658}}, \"EndTime\": 1585690587.060885, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1585690587.060849}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:27 INFO 140475577349952] #quality_metric: host=algo-1, epoch=13, train mse_objective <loss>=0.988136175246\u001b[0m\n",
      "\u001b[34m[2020-03-31 21:36:27.078] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 41, \"duration\": 16, \"num_examples\": 6, \"num_bytes\": 399456}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_mse_objective\": {\"count\": 1, \"max\": 3980.6743007990867, \"sum\": 3980.6743007990867, \"min\": 3980.6743007990867}}, \"EndTime\": 1585690587.079028, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1585690587.079}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:27 INFO 140475577349952] #quality_metric: host=algo-1, epoch=13, validation mse_objective <loss>=3980.6743008\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:27 INFO 140475577349952] #early_stopping_criteria_metric: host=algo-1, epoch=13, criteria=mse_objective, value=3980.6743008\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:27 INFO 140475577349952] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 22, \"sum\": 22.0, \"min\": 22}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 22, \"sum\": 22.0, \"min\": 22}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 21020, \"sum\": 21020.0, \"min\": 21020}, \"Total Batches Seen\": {\"count\": 1, \"max\": 320, \"sum\": 320.0, \"min\": 320}, \"Total Records Seen\": {\"count\": 1, \"max\": 306280, \"sum\": 306280.0, \"min\": 306280}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 21020, \"sum\": 21020.0, \"min\": 21020}, \"Reset Count\": {\"count\": 1, \"max\": 16, \"sum\": 16.0, \"min\": 16}}, \"EndTime\": 1585690587.07969, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1585690586.983879}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:27 INFO 140475577349952] #throughput_metric: host=algo-1, train throughput=219099.365497 records/second\u001b[0m\n",
      "\u001b[34m[2020-03-31 21:36:27.154] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 31, \"duration\": 74, \"num_examples\": 22, \"num_bytes\": 1597520}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_mse_objective\": {\"count\": 1, \"max\": 0.9874550606863839, \"sum\": 0.9874550606863839, \"min\": 0.9874550606863839}}, \"EndTime\": 1585690587.154953, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1585690587.154871}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:27 INFO 140475577349952] #quality_metric: host=algo-1, epoch=14, train mse_objective <loss>=0.987455060686\u001b[0m\n",
      "\u001b[34m[2020-03-31 21:36:27.173] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 44, \"duration\": 16, \"num_examples\": 6, \"num_bytes\": 399456}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_mse_objective\": {\"count\": 1, \"max\": 3978.7206288051752, \"sum\": 3978.7206288051752, \"min\": 3978.7206288051752}}, \"EndTime\": 1585690587.173972, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1585690587.173934}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:27 INFO 140475577349952] #quality_metric: host=algo-1, epoch=14, validation mse_objective <loss>=3978.72062881\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:27 INFO 140475577349952] #early_stopping_criteria_metric: host=algo-1, epoch=14, criteria=mse_objective, value=3978.72062881\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:27 INFO 140475577349952] Early stop condition met. Stopping training.\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:27 INFO 140475577349952] #progress_metric: host=algo-1, completed 100 % epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 22, \"sum\": 22.0, \"min\": 22}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 22, \"sum\": 22.0, \"min\": 22}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 21020, \"sum\": 21020.0, \"min\": 21020}, \"Total Batches Seen\": {\"count\": 1, \"max\": 342, \"sum\": 342.0, \"min\": 342}, \"Total Records Seen\": {\"count\": 1, \"max\": 327300, \"sum\": 327300.0, \"min\": 327300}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 21020, \"sum\": 21020.0, \"min\": 21020}, \"Reset Count\": {\"count\": 1, \"max\": 17, \"sum\": 17.0, \"min\": 17}}, \"EndTime\": 1585690587.174791, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1585690587.079972}\n",
      "\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:27 INFO 140475577349952] #throughput_metric: host=algo-1, train throughput=221381.988675 records/second\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:27 WARNING 140475577349952] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:27 WARNING 140475577349952] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[2020-03-31 21:36:27.192] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 47, \"duration\": 16, \"num_examples\": 6, \"num_bytes\": 399456}\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:27 INFO 140475577349952] #early_stopping_criteria_metric: host=algo-1, epoch=14, criteria=mse_objective, value=3978.72062881\u001b[0m\n",
      "\u001b[34m[2020-03-31 21:36:27.213] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 49, \"duration\": 17, \"num_examples\": 6, \"num_bytes\": 399456}\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:27 INFO 140475577349952] #validation_score (algo-1) : ('mse_objective', 3989.4656820776254)\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:27 INFO 140475577349952] #validation_score (algo-1) : ('mse', 3989.4656820776254)\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:27 INFO 140475577349952] #validation_score (algo-1) : ('absolute_loss', 30.662572387509513)\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:27 INFO 140475577349952] #quality_metric: host=algo-1, validation mse_objective <loss>=3989.46568208\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:27 INFO 140475577349952] #quality_metric: host=algo-1, validation mse <loss>=3989.46568208\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:27 INFO 140475577349952] #quality_metric: host=algo-1, validation absolute_loss <loss>=30.6625723875\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:27 INFO 140475577349952] Best model found for hyperparameters: {\"lr_scheduler_step\": 10, \"wd\": 4.420034520072575e-06, \"optimizer\": \"sgd\", \"lr_scheduler_factor\": 0.99, \"l1\": 0.0, \"learning_rate\": 0.005, \"lr_scheduler_minimum_lr\": 1e-05}\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:27 INFO 140475577349952] Saved checkpoint to \"/tmp/tmpKX8_Er/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[03/31/2020 21:36:27 INFO 140475577349952] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 1581.8779468536377, \"sum\": 1581.8779468536377, \"min\": 1581.8779468536377}, \"finalize.time\": {\"count\": 1, \"max\": 39.430856704711914, \"sum\": 39.430856704711914, \"min\": 39.430856704711914}, \"initialize.time\": {\"count\": 1, \"max\": 125.33187866210938, \"sum\": 125.33187866210938, \"min\": 125.33187866210938}, \"check_early_stopping.time\": {\"count\": 16, \"max\": 1.2440681457519531, \"sum\": 12.543201446533203, \"min\": 0.20384788513183594}, \"setuptime\": {\"count\": 1, \"max\": 22.91703224182129, \"sum\": 22.91703224182129, \"min\": 22.91703224182129}, \"update.time\": {\"count\": 15, \"max\": 113.54708671569824, \"sum\": 1323.383092880249, \"min\": 74.97882843017578}, \"epochs\": {\"count\": 1, \"max\": 100, \"sum\": 100.0, \"min\": 100}}, \"EndTime\": 1585690587.219787, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\"}, \"StartTime\": 1585690585.710193}\n",
      "\u001b[0m\n",
      "Training seconds: 63\n",
      "Billable seconds: 63\n"
     ]
    }
   ],
   "source": [
    "linear_attached = sagemaker.estimator.Estimator.attach(linear_hp_tuner.best_training_job())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##linear_transformer = linear_attached.transformer(instance_count=1, instance_type='ml.m4.xlarge')\n",
    "##linear_transformer.transform(test_location, content_type='text/csv', split_type='Line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!CPU times: user 248 ms, sys: 12.4 ms, total: 260 ms\n",
      "Wall time: 7min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# Deploy and create a predictor\n",
    "linear_predictor = linear_attached.deploy(initial_instance_count=1, instance_type='ml.t2.medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###s3_input_train = sagemaker.s3_input(s3_data='starbucks_data/train.csv', content_type='csv')\n",
    "###s3_input_test = sagemaker.s3_input(s3_data='starbucks_data/test.csv', content_type='csv')\n",
    "###\n",
    "###s3_input_train = sagemaker.s3_input(s3_data='starbucks_data/train.csv', content_type='csv')\n",
    "###s3_input_test = sagemaker.s3_input(s3_data='starbucks_data/test.csv', content_type='csv')\n",
    "###\n",
    "###s3_input_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "import ast\n",
    "\n",
    "# code to evaluate the endpoint on test data\n",
    "# returns the r2 score of the model\n",
    "def evaluate(predictor, X, y):\n",
    "    \"\"\"\n",
    "    Evaluate a model on a test set given the prediction endpoint.  \n",
    "    Return r2 score regression metric.\n",
    "    :param predictor: A prediction endpoint\n",
    "    :param test_features: Test features\n",
    "    :param test_labels: Value labels for test data\n",
    "    :return: R2 score of the mode.\n",
    "    \"\"\"\n",
    "    # LinearLearner produces a `score` for each data point\n",
    "    \n",
    "    ## WITHOUT HyperparameterTuner\n",
    "    #predictions = predictor.predict(X)\n",
    "    #return predictions\n",
    "    ##y_pred = [x['score'] for x in predictions['predictions']]\n",
    "    ##return r2_score(y, y_pred)\n",
    "    \n",
    "    # WITH HyperparameterTuner\n",
    "    predictions = predictor.predict(X).decode('utf-8')\n",
    "    predictions = ast.literal_eval(predictions)\n",
    "    y_pred = np.array([x['score'] for x in predictions['predictions']])\n",
    "    return r2_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import csv_serializer\n",
    "\n",
    "# We need to tell the endpoint what format the data we are sending is in\n",
    "linear_predictor.content_type = 'text/csv'\n",
    "linear_predictor.serializer = csv_serializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08003991937469679\n"
     ]
    }
   ],
   "source": [
    "r2_score = evaluate(linear_predictor, X_test, y_test)\n",
    "print(r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already deleted: linear-learner-200331-2133-002-253df336\n"
     ]
    }
   ],
   "source": [
    "# Deletes a precictor.endpoint\n",
    "def delete_endpoint(predictor):\n",
    "    try:\n",
    "        boto3.client('sagemaker').delete_endpoint(EndpointName=predictor.endpoint)\n",
    "        print('Deleted {}'.format(predictor.endpoint))\n",
    "    except:\n",
    "        print('Already deleted: {}'.format(predictor.endpoint))\n",
    "\n",
    "# delete the predictor endpoint \n",
    "delete_endpoint(linear_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
